<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Research | NUS Neuromorphic Group</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://nusneuromorphic.github.io/research/">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><link href="../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="assets/css/typeplate.css">
<link rel="stylesheet" media="screen" href="http://openfontlibrary.org/face/railway-sans" type="text/css">
<meta name="author" content="nusneuromorphic">
<meta property="og:site_name" content="NUS Neuromorphic Group">
<meta property="og:title" content="Research">
<meta property="og:url" content="https://nusneuromorphic.github.io/research/">
<meta property="og:description" content="Research Topics
Event-based Vision

Supervised learning and low-power processing of data from event based cameras
such as dynamic vision sensor (DVS), Asynchronous Time-based Image Sensor (ATIS) etc.,">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2019-01-22T18:54:11+08:00">
</head>
<body>
<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="container">
    <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="https://nusneuromorphic.github.io/">NUS Neuromorphic Group</a>
    </div>
    <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
<li>
<a href="../labmembers/index.html">Lab Members</a>
                </li>
<li>
<a href="#">Research</a>
                </li>
<li>
<a href="../code/index.html">Code</a>
                </li>
<li>
<li>
  <a href="../dataset/index.html">Dataset</a>
                  </li>
<li>                    
<a href="../openings/index.html">Openings</a>
                </li>
<li>
<a href="../contact/index.html">Contact</a>

        </li>
</ul>
<!-- <ul class="nav navbar-nav navbar-right"> --><ul class="nav navbar-nav navbar-left">
<!--Add Links to social media sites --><!-- pass -->
</ul>
</div>
<!-- /.navbar-collapse -->
    </div>
</nav><!-- End of Menubar --><div class="container">
  <!--Body content-->
  <div class="row">
      
      
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Research</a></h1>

        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<h2><strong>Research Topics</strong></h2>
<h3>Event-based Vision</h3>
<blockquote>
<p>Supervised learning and low-power processing of data from event based cameras
such as dynamic vision sensor (DVS), Asynchronous Time-based Image Sensor (ATIS) etc., is another major focus of research in our team. 
We are looking to use reconfigurable hardware, such as FPGAs, and ARM processors, for implementation of novel event-based algorithms
for power efficient computing.
</p>
<p align="center">
  <iframe width="512" height="288" src="https://www.youtube.com/embed/h3SgXa47Kjc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>
<p>The Xilinx Zynq-7020 FPGA was interfaced to a down-looking DAVIS camera, on-board an unmanned aerial vehicle, recognizing different objects beneath it. </p>
<p>We have also used this setup for real-time object tracking and classification using a hybrid neuromorphic framework.
</p>
<p align="center">
  <iframe width="512" height="288" src="https://www.youtube.com/embed/rPkg_v-v7lY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p> 
<p>Besides low-power hardware implementations, we also carry out academically oriented work for object tracking, learning and detection.</p>
<p></p>
<p align="center">
  <iframe width="512" height="288" src="https://www.youtube.com/embed/3cigR9Al23A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p> 
</blockquote>
<h3>Spiking Neural Networks</h3>
<blockquote>
<p>Spiking Neural Networks use biologically plausible models of neuron as their computational unit.
It is one of the major foucus of our research, especially supervised learning for processing data from event based senosrs
such as silicon retina, silicon cochlea etc.
We are also looking to configure spiking neural networks for implementation in neuromorphic hardwares
for power efficient computing.
</p>
<p align="center">
  <iframe width="512" height="288" src="https://www.youtube.com/embed/JGdatqqci5o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p> 
</blockquote>
<h2><strong>Publications</strong></h2>
<h3>Journals</h3>
<blockquote>
<p>Bharath Ramesh, Shihao Zhang, Hong Yang, Andres Ussa, Matthew Ong, Garrick Orchard, Cheng Xiang., "e-TLD: Event-based Framework for Dynamic Object Tracking", <i> arXiv preprint arXiv:2009.00855 [cs.CV], </i> 2020 <a href="https://arxiv.org/abs/2009.00855"> link</a>, <a href="https://drive.google.com/file/d/1XFyecJoWADdLQX-hU5uig0QL-_i7ydD5/view"> video</a> </p>
<p>Andres Ussa, Chockalingam Senthil Rajen, Deepak Singla, Jyotibdha Acharya, Gideon Fu Chuanrong, Arindam Basu, Bharath Ramesh., "A Hybrid Neuromorphic Object Tracking and Classification Framework for Real-time Systems", <i> arXiv preprint arXiv:2007.11404 [cs.CV], </i> 2020 <a href="https://arxiv.org/abs/2007.11404"> link</a>, <a href="https://tinyurl.com/ycc2tn5t"> video</a> </p>
<p>Deepak Singla, Vivek Mohan, Tarun Pulluri, Andres Ussa, Bharath Ramesh, Arindam Basu., "EBBINNOT: A Hardware Efficient Hybrid Event-Frame Tracker for Stationary Neuromorphic Vision Sensors", <i> arXiv preprint arXiv:2006.00422 [cs.CV], </i> 2020 <a href="https://arxiv.org/abs/2006.00422"> link</a></p>
<p>Bharath Ramesh, Andr√©s Ussa, Luca Della Vedova, Hong Yang and Garrick Orchard., "Low-power Dynamic Object Detection and Classification with Freely Moving Event Cameras" <i>Frontiers in Neuroscience (Accepted)</i>, Feb. 2020 <a href="https://www.frontiersin.org/articles/10.3389/fnins.2020.00135/abstract"> link</a></p>
<p>Ramesh B., Yang H., Orchard G., Le Thi N., Zhang S. and Xiang C. "DART: Distribution Aware Retinal Transform for Event-based Cameras" <i>IEEE Transactions on Pattern Analysis and Machine Intelligence,  DOI: 10.1109/TPAMI.2019.2919301</i>, May 2019 <a href="https://ieeexplore.ieee.org/document/8723171"> link</a></p>
<p>Zhen X., Sheng Y.C. and Orchard, G. "Event-based Stereo Depth Estimation Using Belief Propagation" <i>Frontiers in Neuroscience vol. 11, pp. 535</i>, Oct. 2017 <a href="https://www.frontiersin.org/articles/10.3389/fnins.2017.00535/full"> link</a></p>
</blockquote>
<h3>Conference proceedings</h3>
<blockquote>
<p>Weng Fei Low, Zhi Gao, Cheng Xiang, Bharath Ramesh., "SOFEA: A Non-Iterative and Robust Optical Flow Estimation Algorithm for Dynamic Vision Sensors",<i> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops,</i> June 2020 <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w6/Low_SOFEA_A_Non-Iterative_and_Robust_Optical_Flow_Estimation_Algorithm_for_CVPRW_2020_paper.pdf"> PDF</a></p>
<p>Bharath Ramesh, Hong Yang., "Boosted Kernelized Correlation Filters for Event-based Face Detection", <i> Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops, </i> March 2020 <a href="https://openaccess.thecvf.com/content_WACVW_2020/papers/w5/Ramesh_Boosted_Kernelized_Correlation_Filters_for_Event-based_Face_Detection_WACVW_2020_paper.pdf"> PDF</a></p>
<p>Deepak Singla, Soham Chatterjee, Lavanya Ramapantulu, Andres Ussa, Bharath Ramesh, and Arindam Basu, "HyNNA: Improved Performance for Neuromorphic Vision Sensor Based Surveillance Using Hybrid Neural Network Architecture", <i>IEEE International Symposium on Circuits and Systems (ISCAS) </i>, Sevilla, Spain, May 2020 (Accepted)</p>
<p>Andres Ussa, Luca Della Vedova, Vandana Reddy Padala, Deepak Singla, Jyotibdha Acharya, Charles Zhang Lei, Garrick Orchard, Arindam Basu, Bharath Ramesh., "A low-power end-to-end hybrid neuromorphic framework for surveillance applications", <i>British Machine Vision Conference Workshops</i>, Cardiff, United Kingdom, Sep 2019 <a href="https://arxiv.org/pdf/1910.09806.pdf"> PDF</a>, <a href="https://drive.google.com/file/d/189K3OenAUx4r5qwh_8yQ8vvh8P_Rgavf/edit"> video</a> </p>
<p>Jyotibdha Acharya, Andres Ussa Caycedo, Vandana Reddy Padala, Rishi Raj Sidhu Singh, Garrick Orchard, Bharath Ramesh, Arindam Basu., "EBBIOT: A Low-complexity Tracking Algorithm for Surveillance in IoVT Using Stationary Neuromorphic Vision Sensors", <i>IEEE International System-on-Chip Conference (SOCC)</i>, Singapore, Sep 2019 <a href="https://arxiv.org/pdf/1910.01851.pdf"> PDF</a>, <a href="https://www.youtube.com/watch?v=qnJI8skk4TM&amp;feature=emb_logo"> video</a> </p>
<p>Shrestha S.B. and Orchard G. "SLAYER: Spike Layer Error Reassignment in Time", <i>Neural Information Processing Systems </i>, Montreal, Canada, Dec 2018 <a href="https://papers.nips.cc/paper/7415-slayer-spike-layer-error-reassignment-in-time.pdf"> PDF</a>, <a href="https://www.youtube.com/watch?v=JGdatqqci5o"> video</a> </p>
<p>Ramesh B., Ussa Caycedo A. C., Della Vedova L., Yang H. and Orchard G. "PCA-RECT: An Energy-efficient Object Detection Approach for Event Cameras", <i>Asian Conference on Computer Vision</i>, Perth, Australia, Dec 2018</p>
<p>Colonnier F., Della Vedova L., Teo R.S.H and Orchard G. "Obstacle Avoidance using Eventbased Visual Sensor and Time-To-Contact Processing", <i>Australasian Conference on Robotics and Automation</i>, Lincoln, New Zealand, Dec 2018 <a href="https://ssl.linklings.net/conferences/acra/acra2018_proceedings/views/includes/files/pap104s1-file1.pdf"> PDF</a>, <a href="https://linklings.s3.amazonaws.com/organizations/acra/acra2018/submissions/stype101/UGjfY-pap104s1-file2.mp4"> video</a></p>
<p>Ramesh B., Zhang S., Lee Z.W., Gao Z., Orchard G. and Xiang C. "Long-term Object Tracking with a Moving Event Camera", <i>British Machine Vision Conference</i>, Newcastle, England, Sept 2018 <a href="http://bmvc2018.org/contents/papers/0814.pdf"> PDF</a>, <a href="https://youtu.be/3cigR9Al23A"> video</a></p>
<p>Tun Aung M., Teo R. and Orchard G. ‚ÄúEvent-based Plane-fitting Optical Flow for Dynamic Vision Sensors in FPGA‚Äù <i>IEEE Int. Symp. Circuits Syst.</i>, Florence, Italy, May 2018</p>
<p>Ramesh B., Le Thi N., Orchard G. and Xiang C. "Spike Context: A Neuromorphic Descriptor for Pattern Recognition", <i>IEEE Biomed. Circuits Syst.</i>, Turin, Italy, Oct 2017</p>
<p>Czech D. and Orchard G. "Evaluating Noise Filtering for Event-based Asynchronous Change Detection Image Sensors" <i>6th IEEE RAS &amp; EMBS International Conference on Biomedical Robotics and Biomechatronics (BioRob)</i>, Singapore, June 2016</p>
</blockquote>
</div>
    </div>
    

</article>
</div>

  <div class="footerbox">
    Contents ¬© 2021         <a href="mailto:nusneuromorphic@gmail.com">nusneuromorphic</a>     
    
  </div>
<!--End of body content-->
</div>

            <script src="../assets/js/all-nocdn.js"></script><!-- Add Jumbotron scroll js --><script type="text/javascript">//<![CDATA[
$(window).load(function(){
  $(window).scroll(function() {
    var scrolledY = $(window).scrollTop();
    $('.jumbotron').css('background-position', 'left ' + ((scrolledY)) + 'px');
  });
});//]]>
</script><!-- fancy dates --><script>
moment.locale("en");
fancydates(0, "YYYY-MM-DD HH:mm");
</script><!-- end fancy dates --><script>
baguetteBox.run('div#content', {
    ignoreClass: 'islink',
    captions: function(element) {
        return element.getElementsByTagName('img')[0].alt;
}});
</script><!-- Abstract hide/show
<script src"/assets/js/div_toggle.js"></script>
--><script type="text/javascript">
function toggle(showHideDiv, switchTextDiv) {
    var ele = document.getElementById(showHideDiv);
    var text = document.getElementById(switchTextDiv);
    if(ele.style.display == "none") {
        ele.style.display = "block";
        text.innerHTML = "[hide abstract]";
    }
    else {
            ele.style.display = "none";
            text.innerHTML = "[show abstract]";
    }
}
</script>
</body>
</html>
